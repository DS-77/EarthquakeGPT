# EarthquakeGPT

Abstract: 


### Comparative Analysis:

|      Models      | MAE | MSE | RMSE | MAPE | $R^2$ |
|:----------------:|:---:|:---:|:----:|:----:|:-----:|
|       KAN        |     |     |      |      |       |
|       GRU        |     |     |      |      |       |  
|       LSTM       |     |     |      |      |       |
|   Transformer    |     |     |      |      |       |
| TimeMixer (SOTA) |     |     |      |      |       |
| PatchTST (SOTA)  |     |     |      |      |       |
|   GPT 2 (Ours)   |     |     |      |      |       |

### Dataset

### How to run our model:

### Credit

In this project we utilised:

- [Nixtla](https://nixtlaverse.nixtla.io/) Library:
```
@misc{olivares2022library_neuralforecast,
    author={Kin G. Olivares and
            Cristian Chall√∫ and
            Federico Garza and
            Max Mergenthaler Canseco and
            Artur Dubrawski},
    title = {{NeuralForecast}: User friendly state-of-the-art neural forecasting models.},
    year={2022},
    howpublished={{PyCon} Salt Lake City, Utah, US 2022},
    url={https://github.com/Nixtla/neuralforecast}
}
```
- [OpenAI](https://openai.com/) GPT2 