model_name: GPT-2
settings:
  max_length: 128
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  lr: 1e-5
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  num_epoch: 5
  weight_decay: 0.01
  warmup_steps: 500
  label_smoothing_factor: 0.1
  gradient_accumulation_steps: 1
  logging_steps: 100
  save_total_limit: 2
  train_data_path: "./Data/train.csv"
  test_data_path: "./Data/test.csv"
  out_dir: "./runs"
  load_weights: "./runs/train/fine-tuned-gpt2"
  state_files: "./Data/state_files"